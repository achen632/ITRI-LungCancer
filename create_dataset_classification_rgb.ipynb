{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process images and create labels for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.storage.blob import BlobServiceClient\n",
    "from pydicom import dcmread\n",
    "from io import BytesIO\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pylidc as pl\n",
    "\n",
    "try:\n",
    "    with open('/home/andrew/ITRI-LungCancer/keys.txt', 'r') as file:\n",
    "        data = file.read().splitlines()\n",
    "        account_name    = data[0]\n",
    "        account_key     = data[1]\n",
    "        container_name  = data[2]\n",
    "    \n",
    "    blob_service_client = BlobServiceClient(account_url=f\"https://{account_name}.blob.core.windows.net\", credential=account_key)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_name_list = container_client.list_blob_names()\n",
    "except Exception as ex:\n",
    "    print('Exception:')\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean folders\n",
    "!rm -rf /home/andrew/ITRI-LungCancer/dataset_classify_rgb/\n",
    "\n",
    "# Recreate dataset structure\n",
    "!mkdir -p /home/andrew/ITRI-LungCancer/dataset_classify_rgb/images/{train,val,test}\n",
    "!mkdir -p /home/andrew/ITRI-LungCancer/dataset_classify_rgb/labels/{train,val,test}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions for Creating Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_img(img, window_center, window_width):\n",
    "    win_min = window_center - window_width / 2.0\n",
    "    win_max = window_center + window_width / 2.0\n",
    "    img = np.clip(img, win_min, win_max)\n",
    "    img = (img - win_min) / (win_max - win_min)\n",
    "    img = np.uint8(img * 255)\n",
    "    return img\n",
    "\n",
    "def rescale_img(ds, img):\n",
    "    if 'RescaleIntercept' in ds and 'RescaleSlope' in ds:\n",
    "        img = img * ds.RescaleSlope + ds.RescaleIntercept\n",
    "    return img\n",
    "\n",
    "def change_file_num(blob_name, val):\n",
    "    path = blob_name[0:-7]\n",
    "    num = int(blob_name[-7:-4])\n",
    "    return path+str(num+val).zfill(3)+'.dcm'\n",
    "    \n",
    "def get_dicom(blob_name):\n",
    "    blob_client = container_client.get_blob_client(blob_name)\n",
    "    blob_data = blob_client.download_blob().readall()\n",
    "    blob_stream = BytesIO(blob_data)\n",
    "    return dcmread(blob_stream)\n",
    "\n",
    "def get_image(blob_name):\n",
    "    ds = get_dicom(blob_name)\n",
    "    image = rescale_img(ds, ds.pixel_array)\n",
    "    image = window_img(image, -300, 2000)\n",
    "    return image\n",
    "\n",
    "def save_if_annotated(scan, ds, slice_location, blob_name, data_string):\n",
    "    scan_name = blob_name.split('/')[0]\n",
    "    slice_num = blob_name.split('/')[3].split('-')[1]\n",
    "    \n",
    "    for ann_count, ann in enumerate(scan.annotations):\n",
    "        for contour in ann.contours:\n",
    "            if abs(contour.image_z_position - slice_location) < scan.slice_spacing and ann.boolean_mask().sum() > 300:\n",
    "                bbox = ann.bbox()\n",
    "                bbox_x_center = (bbox[1].start + bbox[1].stop) / ds.Columns / 2\n",
    "                bbox_y_center = (bbox[0].start + bbox[0].stop) / ds.Rows / 2\n",
    "                bbox_width = (bbox[1].stop - bbox[1].start)/ds.Columns\n",
    "                bbox_height = (bbox[0].stop - bbox[0].start)/ds.Rows\n",
    "                \n",
    "                image_base = rescale_img(ds, ds.pixel_array)\n",
    "                image_base = window_img(image_base, -300, 2000)\n",
    "                \n",
    "                image_prev = get_image(change_file_num(blob_name, -2))\n",
    "                image_next = get_image(change_file_num(blob_name, 2))\n",
    "                \n",
    "                image = np.stack([image_prev, image_base, image_next], axis=-1)\n",
    "                \n",
    "                filename = f\"{scan_name}_{slice_num}\"\n",
    "                \n",
    "                image_path = f'/home/andrew/ITRI-LungCancer/dataset_classify_rgb/images/{data_string}/{filename}.png'\n",
    "                cv2.imwrite(image_path, image)\n",
    "                \n",
    "                label_path = f'/home/andrew/ITRI-LungCancer/dataset_classify_rgb/labels/{data_string}/{filename}.txt'\n",
    "                label_txt = f\"0 {bbox_x_center} {bbox_y_center} {bbox_width} {bbox_height}\"\n",
    "                with open(label_path, 'w') as file:\n",
    "                    file.write(label_txt)\n",
    "                return True\n",
    "    return False\n",
    "\n",
    "def create_dataset(count, data_string):\n",
    "    # temp = 0\n",
    "    while(count > 0):\n",
    "        blob_name = next(blob_name_list)\n",
    "        ds = get_dicom(blob_name)\n",
    "        \n",
    "        scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == ds.PatientID).first()\n",
    "        slice_location = ds.ImagePositionPatient[2]\n",
    "        \n",
    "        if save_if_annotated(scan, ds, slice_location, blob_name, data_string):\n",
    "            count -= 1\n",
    "            if count > 0:\n",
    "                print(f\"{data_string}: {count}    \", end='\\r', flush=True)\n",
    "            # temp += 1\n",
    "        # if temp > 3:\n",
    "        #     break\n",
    "    print(f\"{data_string} done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6080 1520 400\n",
      "train: 5777    \r"
     ]
    }
   ],
   "source": [
    "total = 8000\n",
    "\n",
    "train_size  = int(total*0.95*0.8)\n",
    "val_size    = int(total*0.95*0.2)\n",
    "test_size   = int(total*0.05)\n",
    "\n",
    "print(train_size, val_size, test_size)\n",
    "\n",
    "create_dataset(train_size, \"train\")\n",
    "create_dataset(val_size, \"val\")\n",
    "create_dataset(test_size, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# !rm -rf runs/\n",
    "\n",
    "model = YOLO(\"/home/andrew/ITRI-LungCancer/YOLO/yolov8m.pt\")\n",
    "results = model.train(data=\"/home/andrew/ITRI-LungCancer/YOLO/dataset_classify_rgb.yaml\",epochs=300,patience=20,cache=True,lr0=1E-2,imgsz=512)\n",
    "model.save('/home/andrew/ITRI-LungCancer/YOLO/model_classify_rgb.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
