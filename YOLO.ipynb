{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process images and create labels for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from pydicom import dcmread\n",
    "from io import BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "import pylidc as pl\n",
    "\n",
    "try:\n",
    "    with open('/home/andrew/ITRI-LungCancer/keys.txt', 'r') as file:\n",
    "        data = file.read().splitlines()\n",
    "        account_name    = data[0]\n",
    "        account_key     = data[1]\n",
    "        container_name  = data[2]\n",
    "    \n",
    "    blob_service_client = BlobServiceClient(account_url=f\"https://{account_name}.blob.core.windows.net\", credential=account_key)\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    blob_name_list = container_client.list_blob_names()\n",
    "except Exception as ex:\n",
    "    print('Exception:')\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organize file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean folders\n",
    "# !rm -rf /home/andrew/ITRI-LungCancer/dataset/\n",
    "!rm -rf /home/andrew/ITRI-LungCancer/runs\n",
    "\n",
    "# Recreate dataset structure\n",
    "# !mkdir -p /home/andrew/ITRI-LungCancer/dataset/images/{train,val}\n",
    "# !mkdir -p /home/andrew/ITRI-LungCancer/dataset/labels/{train,val}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize annotation properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Analyzing bbox sizes\n",
    "# anns = pl.query(pl.Annotation).all()\n",
    "\n",
    "# data = []\n",
    "# for i, ann in enumerate(anns):\n",
    "#     bbox = ann.bbox()\n",
    "#     bbox_width = (bbox[1].stop - bbox[1].start)/512\n",
    "#     bbox_height = (bbox[0].stop - bbox[0].start)/512\n",
    "#     entry = [bbox_width, bbox_height, ann.malignancy, ann.diameter, ann.surface_area, ann.volume]\n",
    "#     data.append(entry)\n",
    "    \n",
    "# df = pd.DataFrame(data, columns=['bbox_width', 'bbox_height', 'malignancy', 'diameter', 'surface_area', 'volume'])\n",
    "# plt.figure(figsize=(20, 20))\n",
    "# for i in range(len(df.columns)):\n",
    "#     plt.subplot(len(df.columns), 1, i+1)\n",
    "#     plt.hist(df[df.columns[i]], bins=50)\n",
    "#     plt.title(df.columns[i], y=0, loc='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_img(img, window_center, window_width):\n",
    "    win_min = window_center - window_width / 2.0\n",
    "    win_max = window_center + window_width / 2.0\n",
    "    img = np.clip(img, win_min, win_max)\n",
    "    img = (img - win_min) / (win_max - win_min)\n",
    "    img = np.uint8(img * 255)\n",
    "    return img\n",
    "\n",
    "def rescale_img(ds, img):\n",
    "    if 'RescaleIntercept' in ds and 'RescaleSlope' in ds:\n",
    "        img = img * ds.RescaleSlope + ds.RescaleIntercept\n",
    "    return img\n",
    "\n",
    "def create_dataset(count, data_string):\n",
    "    while(count > 0):\n",
    "        blob_name = next(blob_name_list)\n",
    "        scan_name = blob_name.split('/')[0]\n",
    "        slice_num = blob_name.split('/')[3].split('-')[1]\n",
    "        \n",
    "        blob_client = container_client.get_blob_client(blob_name)\n",
    "        blob_data = blob_client.download_blob().readall()\n",
    "        blob_stream = BytesIO(blob_data)\n",
    "        ds = dcmread(blob_stream)\n",
    "        \n",
    "        scan = pl.query(pl.Scan).filter(pl.Scan.patient_id == ds.PatientID).first()\n",
    "        slice_location = ds.ImagePositionPatient[2]\n",
    "        \n",
    "        if scan is None:\n",
    "            print(\"No scan found for this patient.\")\n",
    "        else:\n",
    "            for ann_count, ann in enumerate(scan.annotations):\n",
    "                for contour in ann.contours:\n",
    "                    if abs(contour.image_z_position - slice_location) < scan.slice_spacing:\n",
    "                        count -= 1\n",
    "                        if count > 0:\n",
    "                            print(f\"Remaining: {count}    \", end='\\r', flush=True)\n",
    "                        \n",
    "                        bbox = ann.bbox()\n",
    "                        bbox_x_center = (bbox[1].start + bbox[1].stop) / ds.Columns / 2\n",
    "                        bbox_y_center = (bbox[0].start + bbox[0].stop) / ds.Rows / 2\n",
    "                        bbox_width = (bbox[1].stop - bbox[1].start)/ds.Columns\n",
    "                        bbox_height = (bbox[0].stop - bbox[0].start)/ds.Rows\n",
    "                        \n",
    "                        if bbox_width < 0.02 or bbox_height < 0.025:\n",
    "                            continue\n",
    "                        \n",
    "                        image = rescale_img(ds, ds.pixel_array)\n",
    "                        image = window_img(image, -300, 2000)\n",
    "\n",
    "                        filename = f\"{scan_name}_{slice_num}_{ann_count}\"\n",
    "                        \n",
    "                        image_path = f'/home/andrew/ITRI-LungCancer/dataset/images/{data_string}/{filename}.png'\n",
    "                        cv2.imwrite(image_path, image)\n",
    "                        \n",
    "                        label_path = f'/home/andrew/ITRI-LungCancer/dataset/labels/{data_string}/{filename}.txt'\n",
    "                        label_txt = f\"0 {bbox_x_center} {bbox_y_center} {bbox_width} {bbox_height}\"\n",
    "                        with open(label_path, 'w') as file:\n",
    "                            file.write(label_txt)\n",
    "    print(f\"{data_string} done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create_dataset(5800, \"train\")\n",
    "# create_dataset(1000, \"val\")\n",
    "# create_dataset(200, \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
    "    print(f\"GPU Name: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available\")\n",
    "    \n",
    "model = YOLO(\"YOLO/yolov8n.pt\")\n",
    "results = model.train(data=\"YOLO/dataset.yaml\",epochs=100,cache=True,lr0=1E-4,exist_ok=True,save_period=10,imgsz=512)\n",
    "model.save('YOLO/model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('YOLO/model.pt')\n",
    "results = model.val(data='YOLO/dataset.yaml')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
